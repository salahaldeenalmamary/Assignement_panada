{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Domain: E-commerce Retail Transactions\n",
    "\n",
    "Objective:\n",
    "\n",
    "The objective is to extract meaningful patterns, trends, and insights from customer transactions data to improve business strategies, enhance customer experience, and optimize operations.\n",
    "Data Features:\n",
    "\n",
    "Customer ID: Unique identifier for each customer.\n",
    "Age: Age of the customer.\n",
    "Gender: Gender of the customer.\n",
    "Item Purchased: Description of the purchased item.\n",
    "Category: Category to which the item belongs.\n",
    "Purchase Amount (USD): The amount spent on the purchase.\n",
    "Location: Geographic location of the customer.\n",
    "Size: Size of the purchased item.\n",
    "Color: Color of the purchased item.\n",
    "Season: Season associated with the purchase.\n",
    "Review Rating: Rating provided by the customer for the purchased item.\n",
    "Subscription Status: Indicates whether the customer is subscribed to any service.\n",
    "Payment Method: Method used by the customer to make the payment.\n",
    "Shipping Type: Type of shipping chosen by the customer.\n",
    "Discount Applied: Whether a discount was applied to the purchase.\n",
    "Promo Code Used: Indicates whether a promo code was used.\n",
    "Previous Purchases: Number of previous purchases made by the customer.\n",
    "Preferred Payment Method: Customer's preferred payment method.\n",
    "Frequency of Purchases: How frequently the customer makes purchases\n",
    "\n",
    "ecommendation system  specifically a hybrid recommendation system that combines \n",
    "clustering and collaborative filtering. It aims to provide personalized product recommendations to \n",
    "customers based on their behavior and preferences, as well as similarities with other customers in the same cluster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'shopping_trends.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlxtend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfrequent_patterns\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m apriori, association_rules\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshopping_trends.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m df\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Data Preprocessing\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'shopping_trends.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('shopping_trends.csv')\n",
    "df\n",
    "# Data Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Convert 'Frequency of Purchases' to a numeric format?\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "categorical_cols = ['Gender', 'Location', 'Subscription Status', 'Payment Method', 'Item Purchased', 'Shipping Type', 'Promo Code Used', 'Preferred Payment Method', 'Frequency of Purchases']\n",
    "for col in categorical_cols:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Convert 'Frequency of Purchases' to a numeric format\n",
    "df['Frequency of Purchases'] = pd.to_numeric(df['Frequency of Purchases'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for clustering\n",
    "X_clustering = df[['Age', 'Review Rating', 'Previous Purchases', 'Frequency of Purchases']]\n",
    "\n",
    "# Apply K-Means clustering\n",
    "num_clusters = 5  # Adjust the number of clusters as needed\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(X_clustering)\n",
    "\n",
    "# Prepare the data for product recommendation within a specific cluster\n",
    "cluster_number = 2  # Choose the cluster for which you want to make recommendations\n",
    "cluster_data = df[df['Cluster'] == cluster_number]\n",
    "\n",
    "# Prepare the data for collaborative filtering (user-item matrix)\n",
    "user_item_matrix = cluster_data.pivot_table(index='Customer ID', columns='Item Purchased', values='Purchase Amount (USD)', fill_value=0)\n",
    "\n",
    "# Reset index to convert 'Item Purchased' back to a regular column\n",
    "user_item_matrix.reset_index(inplace=True)\n",
    "\n",
    "# Collaborative Filtering: Use RandomForestRegressor as an example\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "target_columns = user_item_matrix.columns[1:]  # Exclude 'Customer ID'\n",
    "X_train = user_item_matrix.drop(target_columns, axis=1)\n",
    "y_train = user_item_matrix[target_columns]\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for the purchase amounts of all products\n",
    "predicted_purchase_all_products = model.predict(X_train)\n",
    "\n",
    "# Select the top products based on predicted purchase amounts\n",
    "top_products = user_item_matrix.columns[1:][predicted_purchase_all_products.mean(axis=0).argsort()[::-1][:5]]  \n",
    "\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(top_products, predicted_purchase_all_products.mean(axis=0)[predicted_purchase_all_products.mean(axis=0).argsort()[::-1][:5]])\n",
    "plt.xlabel('Product')\n",
    "plt.ylabel('Average Predicted Purchase Amount')\n",
    "plt.title('Top Recommended Products')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "\n",
    "# Convert 'Frequency of Purchases' to a numeric format\n",
    "df['Frequency of Purchases'] = pd.to_numeric(df['Frequency of Purchases'], errors='coerce')\n",
    "\n",
    "# Select relevant columns for Apriori\n",
    "apriori_df = df[['Gender', 'Location', 'Subscription Status', 'Payment Method', 'Item Purchased', 'Shipping Type', 'Promo Code Used', 'Preferred Payment Method']]\n",
    "\n",
    "# Convert categorical columns to string type for Apriori\n",
    "apriori_df = apriori_df.astype(str)\n",
    "\n",
    "# Apply Apriori algorithm\n",
    "frequent_itemsets = apriori(apriori_df, min_support=0.1, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "# Display the generated rules\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('shopping_trends.csv')\n",
    "\n",
    "# Encoding categorical variables\n",
    "df_encoded = pd.get_dummies(df[['Item Purchased', 'Category', 'Shipping Type', 'Discount Applied', 'Promo Code Used']])\n",
    "\n",
    "# Concatenate encoded variables with the original DataFrame\n",
    "df = pd.concat([df[['Customer ID']], df_encoded], axis=1)\n",
    "\n",
    "# Apriori algorithm\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.5, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.7)\n",
    "\n",
    "# Display the association rules\n",
    "print(\"Association Rules:\")\n",
    "print(rules[['antecedents', 'consequents', 'confidence']])\n",
    "\n",
    "# Function to recommend products based on a given item\n",
    "def recommend_products(item, rules):\n",
    "    recommended_products = set()\n",
    "    for index, row in rules.iterrows():\n",
    "        if f'{item}_1' in row['antecedents']:\n",
    "            recommended_products.update(row['consequents'])\n",
    "    return recommended_products\n",
    "\n",
    "# Function to recommend products for all items\n",
    "def recommend_products_for_all(df, rules):\n",
    "    all_recommendations = {}\n",
    "    unique_items = df_encoded.columns\n",
    "    \n",
    "    for item in unique_items:\n",
    "        recommended_products = recommend_products(item, rules)\n",
    "        all_recommendations[item] = recommended_products\n",
    "    \n",
    "    return all_recommendations\n",
    "\n",
    "# Example: Recommend products for all items\n",
    "all_recommendations = recommend_products_for_all(df, rules)\n",
    "\n",
    "print(\"\\nProducts recommended for each item:\")\n",
    "for item, recommendations in all_recommendations.items():\n",
    "    print(f\"\\nProducts recommended for '{item}': {recommendations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Sample Data\n",
    "data = {\n",
    "    'Customer ID': [1, 2, 3, 4],\n",
    "    'Age': [55, 19, 50, 21],\n",
    "    'Gender': ['Male', 'Male', 'Male', 'Male'],\n",
    "    'Item Purchased': ['Blouse', 'Sweater', 'Jeans', 'Sandals'],\n",
    "    'Category': ['Clothing', 'Clothing', 'Clothing', 'Footwear'],\n",
    "    'Purchase Amount (USD)': [53, 64, 73, 90],\n",
    "    'Location': ['Kentucky', 'Maine', 'Massachusetts', 'Rhode Island'],\n",
    "    'Size': ['L', 'L', 'S', 'M'],\n",
    "    'Color': ['Gray', 'Maroon', 'Maroon', 'Maroon'],\n",
    "    'Season': ['Winter', 'Winter', 'Spring', 'Spring'],\n",
    "    'Review Rating': [3.1, 3.1, 3.1, 3.5],\n",
    "    'Subscription Status': ['Yes', 'Yes', 'Yes', 'Yes'],\n",
    "    'Payment Method': ['Credit Card', 'Bank Transfer', 'Cash', 'PayPal'],\n",
    "    'Shipping Type': ['Express', 'Express', 'Free Shipping', 'Next Day Air'],\n",
    "    'Discount Applied': ['Yes', 'Yes', 'Yes', 'Yes'],\n",
    "    'Promo Code Used': ['Yes', 'Yes', 'Yes', 'Yes'],\n",
    "    'Previous Purchases': [14, 2, 23, 49],\n",
    "    'Preferred Payment Method': ['Venmo', 'Cash', 'Credit Card', 'PayPal'],\n",
    "    'Frequency of Purchases': ['Fortnightly', 'Fortnightly', 'Weekly', 'Weekly']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply label encoding to categorical columns\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_cols = ['Gender', 'Location', 'Subscription Status', 'Payment Method', 'Item Purchased', \n",
    "                    'Shipping Type', 'Discount Applied', 'Promo Code Used', 'Preferred Payment Method', \n",
    "                    'Frequency of Purchases']\n",
    "for col in categorical_cols:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df[['Customer ID', 'Purchase Amount (USD)', 'Discount Applied', 'Promo Code Used']]\n",
    "\n",
    "# Apriori algorithm\n",
    "frequent_itemsets = apriori(df, min_support=0.1, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.7)\n",
    "\n",
    "# Display the association rules\n",
    "print(\"Association Rules:\")\n",
    "print(rules[['antecedents', 'consequents', 'confidence']])\n",
    "\n",
    "# Filter rules related to Promo Code\n",
    "promo_rules = rules[rules['antecedents'].apply(lambda x: 'Promo Code Used' in x)]\n",
    "\n",
    "# Display rules related to Promo Code\n",
    "print(\"\\nAssociation Rules for Promo Code:\")\n",
    "print(promo_rules[['antecedents', 'consequents', 'confidence']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('shopping_trends.csv')\n",
    "\n",
    "# Encoding categorical variables\n",
    "df_encoded = pd.get_dummies(df[['Discount Applied', 'Promo Code Used', 'Item Purchased']])\n",
    "\n",
    "# Discretize 'Purchase Amount (USD)' into bins\n",
    "df['Purchase Amount (USD)'] = pd.cut(df['Purchase Amount (USD)'], bins=[0, 50, 100, 150], labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "# Ensure the encoded variables are boolean\n",
    "df_encoded = df_encoded.astype(bool)\n",
    "\n",
    "# Concatenate encoded variables with the original DataFrame\n",
    "df = pd.concat([df[['Discount Applied', 'Promo Code Used', 'Purchase Amount (USD)']], df_encoded], axis=1)\n",
    "\n",
    "# Apriori algorithm\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.1, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric='lift', min_threshold=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display the association rules including Purchase Amount (USD)\n",
    "print(\"Association Rules:\")\n",
    "print(rules[['antecedents', 'consequents', 'confidence', 'lift']])\n",
    "\n",
    "# Filter rules related to Purchase Amount (USD)\n",
    "purchase_amount_rules = rules[rules['antecedents'].apply(lambda x: 'Purchase Amount (USD)' in x)]\n",
    "\n",
    "# Display rules related to Purchase Amount (USD)\n",
    "print(\"\\nAssociation Rules for Purchase Amount (USD):\")\n",
    "print(purchase_amount_rules[['antecedents', 'consequents', 'confidence', 'lift']])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='confidence', y='lift', size='support', data=rules)\n",
    "plt.xlabel('Confidence')\n",
    "plt.ylabel('Lift')\n",
    "plt.title('Association Rules - Confidence vs Lift')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
